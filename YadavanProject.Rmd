---
title: "MTH6139 Time Series" 
subtitle: "Coursework 1 -- Analysis of car congestion time series" 
author: "Yadavan Surabaskaran" 
date: "Spring term 2025" 
output: 
  html_document:
    toc: true
    toc_float: true
    theme: spacelab 
    highlight: tango
editor_options: 
  markdown: 
    wrap: 72
---

```{r, echo=FALSE}
# This code will display the QMUL logo at the top right of the page
# Do not change this code
htmltools::img(src = knitr::image_uri("images/QMlogo.png"),
               alt = 'logo',
               style = 'position:absolute; top:0; right:0; padding:10px; width:20%;')
```

# 1. Introduction and motivation

In this project we use Meta's Prophet library to explore the possibility of forecasting traffic congestion. This data is expected to have strong seasonal components, such as daily and weekly, present in the data. This is the type of data for which the Prophet library was designed, therefore it represents a suitable tool for this assignment. 

We use traffic congestion data provided for Kaggle as a representative data set that can be used for testing time series analysis and forecasting models. The results of this project can provide reference points for the ability of machine learning tools to forecast and interpret seasonality in the data.  

# 2. Data description

Before describing the data we load the essential libraries and the data from a csv file downloaded from Kaggle. 

```{r}
pacman::p_load(tidyverse, prophet) # load and if necessary install the libraries tidyverse and prophet. Only the library pacman should be installed manually.
df = read_csv("~/Desktop/Time Series/Yadavan project/data/traffic.csv") #using read_csv which recognises the first column as datetime
table(df$Junction) # printing the number of observations for each junction.
colnames(df) 
df = filter(df,Junction==1) # leaves only observations for junction 1.
```

The dataset used in this project contains information about the number of cars that passed 4 different junctions in the US each hour from 1st November 2015 to 30th June 2017 with 48120 observations in total. In this project we use the first 14592 observations corresponding to the first crossing with no missing observations as proved below. 

```{r}
a = first(df$DateTime)
b = last(df$DateTime)
timediff = as.duration(interval(a,b))/3600 #estimating the difference between the first and the last date in hours. 
as.integer(timediff)+1 #the expected number of hours in the dataframe.
nrow(df) #the actual number of hours in the dataframe. 
```

The original dataset contains 4 variables:
- DateTime, the time corresponding to the beginning of the hour of observation; 
- Junction, number of the junction from 1-4;
- Vehicles, the number of vehicles crossing the junction each hour;
- ID, the ID of each observation
For our analysis we will use only two variables DateTime and Vehicles which we will rename as ds and y. 

```{r}
df = select(df,ds=DateTime,y=Vehicles) #selecting and renaming two columns
```

The mean and the median number of cars crossing the first junction as well as the minimum and maximum are reported below. A higher mean (45.05) than the median (40.00), means that the distribution is right-skewed. We notice substantial variability in the number of cars crossing the junction from 5 to 156.  

```{r}
mean(df$y)
median(df$y)
min(df$y)
max(df$y)
IQR(df$y)
```

# 3. Data analysis

First we will estimate a linear trend coefficient by regressing the time series on the observation number divided by 24\*7=168, which gives us weekly trend. After running linear regression the coefficient associated to the weekly trend is 0.64, which is highly significant. It means that over a year the number of cars is expected to increase by 0.64\*52=33.28 cars. Based on the R-squared = 0.4865 the linear trend captures 48.65% of variance in the data.  

```{r}
t = (1:nrow(df))/(24*7) #t is the number of weeks from a date in the past
model1 = lm(df$y ~ t) #regressing the congestion variable y (hourly) on the week number t
summary(model1)
```


In addition to trend we can also explore daily seasonality by additionally regressing on the 23 dummies related to 24 hours. The dummies were created automatically when converting the hours into factors and regressing y on both t and h. As a result of accounting for seasonality the adjusted R-squared increased to 0.74 compared to 0.4865 for model 1, with only trend. All the dummy coefficients are highly statistically significant. The lowest traffic happens from 5am to 6am (the coefficient at h5 is -21.69 which is the smallest). The busiest hour is between 7pm and 8pm (the coefficient at h19 is 12.99 which is the highest). 

```{r}
h = hour(df$ds) #we create a new variable h for the hour of the day. 
h = as.factor(h) #converting h into factors for a regression with dummies
model2 = lm(df$y ~ t+h) #regressing congestion on the week number and the hourly dummies.
summary(model2)
```

Finally we can apply Meta's library Prophet designed to analyse and visualise time series with trend and seasonality. We forecast the time series 13 weeks (3 months) ahead. The trend is captured well, some seasonality is captured too as the blue line has an oscillating pattern. However the heteroskedasticity, which is evidenced by the increasing oscillations of the data is not captured at all. 

```{r}
model3 = prophet() #initialising the model
model3 = add_country_holidays(model3,country_name = 'US') #adding US holidays to the model
m = fit.prophet(model3,df) #fitting the model
f = make_future_dataframe(m, periods=7*24*13, freq="hours") #specifying the period for forecasting
p = predict(m, f) #forecasting
plot(m,p) #visualising the data in forecasts
```

The Prophet model3 could decompose the data into a trend (which is almost linear) and two seasonal components (hourly and day of the week), and the holiday component for the US, which we specified in the model.  

```{r}
prophet_plot_components(m, p)
```

# Summary of results

Analysing the four components by the Prophet model we can conclude:
- There is an almost linear trend in the congestion data.
- Congestion varies significantly on holidays, for example there is a drop in congestion on Christmas and New Year.
- There is a strong weekly seasonality in the data, with the highest level of congestion on Tuesday, whereas Sunday has the least congestion.
- Hourly seasonality is also strong, which was additionally confirmed by a linear regression model with hourly dummies, with the time around midday and evening being the most congested and morning being the least congested. 

Despite its convenience to describe seasonality, the prophet model could not identify the obvious heteroskedasticity in the data.

The current report along with the data can be found on GitHub at
<https://github.com/yadavanqmul/trafficcongestion>.


# References
-   Kaggle traffic congestion data:
    <https://www.kaggle.com/datasets/fedesoriano/traffic-prediction-dataset/data>
-   Prophet library for R manual:
    <https://cran.r-project.org/web/packages/prophet/prophet.pdf>
-   Yadavan Surabaskaran (2025), traffic congestion report with data:
    <https://github.com/yadavanqmul/trafficcongestion>